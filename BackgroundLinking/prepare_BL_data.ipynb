{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b073fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers\n",
    "from elasticsearch import Elasticsearch, TransportError\n",
    "import argparse\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "from tqdm.auto import tqdm\n",
    "import xmltodict\n",
    "import urllib\n",
    "import json\n",
    "import sys\n",
    "\n",
    "TREC_YEAR = 2021 # 2019, using V2 for both\n",
    "TREC_DATAFILES_DIR = \"/DATA/users/kenanfayoumi/EntityRanking/trec_files\"\n",
    "\n",
    "with open(f'{TREC_DATAFILES_DIR}/num_to_docid_mapping_TREC{TREC_YEAR}.json', 'r') as fp:\n",
    "    num_to_docid_mapping=json.load(fp)\n",
    "docid_to_num_mapping  = {v: k for k, v in num_to_docid_mapping.items()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "520211b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a138c20348924f36bc7afc874d36f0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=700000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topics_jsons = []\n",
    "\n",
    "\n",
    "with open(\"/DATA/projects/TRECNews/WAPO/WashingtonPost.v4/data/TREC_Washington_Post_collection.v4.jl\",'rb') as f:\n",
    "# with open(\"/DATA/projects/TRECNews/WAPO/WashingtonPost.v3/data/TREC_Washington_Post_collection.v3.jl\",'rb') as f:\n",
    "# with open(\"/DATA/projects/TRECNews/WAPO/WashingtonPost.v2/data/TREC_Washington_Post_collection.v2.jl\",'rb') as f:\n",
    "    for line in tqdm(f, total=700000):\n",
    "        js = json.loads(line)\n",
    "        if js['id'] in docid_to_num_mapping:\n",
    "            topics_jsons.append(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d5f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_year = 2020\n",
    "\n",
    "with open(f\"data_files/{trec_year}_topics_json_contents.jsonl\",'w') as f:\n",
    "    for obj in topics_jsons:\n",
    "        f.write(json.dumps(obj)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d650e7",
   "metadata": {},
   "source": [
    "# get article text contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b98d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get the text content for all of these articles\n",
    "needed_article_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a9be1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all years qrels needed articles\n",
    "articles_linking = dict()\n",
    "\n",
    "qrels_file =\"/DATA/projects/TRECNews/2018/bl/bqrels.exp-gains.txt\"\n",
    "with open(qrels_file,'r') as file:\n",
    "  for line in file.readlines():\n",
    "    splitted = line.split()\n",
    "    links = []\n",
    "    if(splitted[0] in articles_linking):\n",
    "      links = articles_linking[splitted[0]]\n",
    "    links.append([splitted[2],splitted[3]])\n",
    "    links = sorted(links,key= lambda x: int(x[1]),reverse=True)\n",
    "    articles_linking[splitted[0]] = links\n",
    "    \n",
    "qrels_file = \"/DATA/projects/TRECNews/2019/bl/newsir19-qrels-background.txt\"\n",
    "with open(qrels_file,'r') as file:\n",
    "  for line in file.readlines():\n",
    "    splitted = line.split()\n",
    "    links = []\n",
    "    if(splitted[0] in articles_linking):\n",
    "      links = articles_linking[splitted[0]]\n",
    "    links.append([splitted[2],splitted[3]])\n",
    "    links = sorted(links,key= lambda x: int(x[1]),reverse=True)\n",
    "    articles_linking[splitted[0]] = links\n",
    "    \n",
    "qrels_file = \"/DATA/projects/TRECNews/2020/bl/qrels.background\"\n",
    "with open(qrels_file,'r') as file:\n",
    "  for line in file.readlines():\n",
    "    splitted = line.split()\n",
    "    links = []\n",
    "    if(splitted[0] in articles_linking):\n",
    "      links = articles_linking[splitted[0]]\n",
    "    links.append([splitted[2],splitted[3]])\n",
    "    links = sorted(links,key= lambda x: int(x[1]),reverse=True)\n",
    "    articles_linking[splitted[0]] = links\n",
    "    \n",
    "qrels_file = \"/DATA/projects/TRECNews/2021/bl/qrels.background\"\n",
    "with open(qrels_file,'r') as file:\n",
    "  for line in file.readlines():\n",
    "    splitted = line.split()\n",
    "    links = []\n",
    "    if(splitted[0] in articles_linking):\n",
    "      links = articles_linking[splitted[0]]\n",
    "    links.append([splitted[2],splitted[3]])\n",
    "    links = sorted(links,key= lambda x: int(x[1]),reverse=True)\n",
    "    articles_linking[splitted[0]] = links\n",
    "    \n",
    "\n",
    "with open(f\"data_files/articles_linking.json\",'w') as f:\n",
    "    json.dump(articles_linking,f)\n",
    "    \n",
    "    \n",
    "needed_article_ids += [pair[0] for list_of_pairs in articles_linking.values() for pair in list_of_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e6becfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test topics ids\n",
    "TREC_DATAFILES_DIR = \"/DATA/users/kenanfayoumi/EntityRanking/trec_files\"\n",
    "\n",
    "TREC_YEAR = 2018 # 2019, using V2 for both\n",
    "with open(f'{TREC_DATAFILES_DIR}/num_to_docid_mapping_TREC{TREC_YEAR}.json', 'r') as fp:\n",
    "    num_to_docid_mapping=json.load(fp)\n",
    "needed_article_ids += list(num_to_docid_mapping.values())\n",
    "\n",
    "TREC_YEAR = 2019 # 2019, using V2 for both\n",
    "with open(f'{TREC_DATAFILES_DIR}/num_to_docid_mapping_TREC{TREC_YEAR}.json', 'r') as fp:\n",
    "    num_to_docid_mapping=json.load(fp)\n",
    "needed_article_ids += list(num_to_docid_mapping.values())\n",
    "\n",
    "TREC_YEAR = 2020 # 2019, using V2 for both\n",
    "with open(f'{TREC_DATAFILES_DIR}/num_to_docid_mapping_TREC{TREC_YEAR}.json', 'r') as fp:\n",
    "    num_to_docid_mapping=json.load(fp)\n",
    "needed_article_ids += list(num_to_docid_mapping.values())\n",
    "\n",
    "TREC_YEAR = 2021 # 2019, using V2 for both\n",
    "with open(f'{TREC_DATAFILES_DIR}/num_to_docid_mapping_TREC{TREC_YEAR}.json', 'r') as fp:\n",
    "    num_to_docid_mapping=json.load(fp)\n",
    "needed_article_ids += list(num_to_docid_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15b50587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also get all baseline candidates\n",
    "with open('res_files/wapoV2_BASELINE_2018','r') as file:\n",
    "  for line in file.readlines():\n",
    "    splitted = line.split()\n",
    "    needed_article_ids.append(splitted[2])\n",
    "\n",
    "with open('res_files/wapoV2_BASELINE_2019','r') as file:\n",
    "  for line in file.readlines():\n",
    "    splitted = line.split()\n",
    "    needed_article_ids.append(splitted[2])\n",
    "    \n",
    "    \n",
    "with open('res_files/wapoV4_BASELINE_2020','r') as file:\n",
    "  for line in file.readlines():\n",
    "    splitted = line.split()\n",
    "    needed_article_ids.append(splitted[2])\n",
    "    \n",
    "with open('res_files/wapoV4_BASELINE_2021','r') as file:\n",
    "  for line in file.readlines():\n",
    "    splitted = line.split()\n",
    "    needed_article_ids.append(splitted[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e8cb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_article_ids = list(set(needed_article_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f42506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_content_by_type(jsarr, t, field='content'):\n",
    "    strings = [c[field] for c in jsarr if c is not None and c['type'] == t and field in c and c[field] is not None]\n",
    "    if strings:\n",
    "        return ' '.join(strings)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba284c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cd081a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a03e3cf3cc408094f07b5a3b4168e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=700000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adb1f185d4245cba8f23224e2838aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=700000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d9eb3c355b453491dc25d60ce179ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=700000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "article_texts = {}\n",
    "\n",
    "with open(\"/DATA/projects/TRECNews/WAPO/WashingtonPost.v4/data/TREC_Washington_Post_collection.v4.jl\",'rb') as f:\n",
    "    for line in tqdm(f, total=700000):\n",
    "        js = json.loads(line)\n",
    "        if js['id'] in needed_article_ids:\n",
    "            text = get_all_content_by_type(js['contents'], 'sanitized_html')\n",
    "            if text:\n",
    "                text = re.sub('<.*?>', ' ', text)\n",
    "                article_texts[js['id']] = text\n",
    "            \n",
    "with open(\"/DATA/projects/TRECNews/WAPO/WashingtonPost.v3/data/TREC_Washington_Post_collection.v3.jl\",'rb') as f:\n",
    "# with open(\"/DATA/projects/TRECNews/WAPO/WashingtonPost.v2/data/TREC_Washington_Post_collection.v2.jl\",'rb') as f:\n",
    "    for line in tqdm(f, total=700000):\n",
    "        js = json.loads(line)\n",
    "        if js['id'] in needed_article_ids:\n",
    "            text = get_all_content_by_type(js['contents'], 'sanitized_html')\n",
    "            if text:\n",
    "                text = re.sub('<.*?>', ' ', text)\n",
    "                article_texts[js['id']] = text\n",
    "            \n",
    "            \n",
    "with open(\"/DATA/projects/TRECNews/WAPO/WashingtonPost.v2/data/TREC_Washington_Post_collection.v2.jl\",'rb') as f:\n",
    "    for line in tqdm(f, total=700000):\n",
    "        js = json.loads(line)\n",
    "        if js['id'] in needed_article_ids:\n",
    "            text = get_all_content_by_type(js['contents'], 'sanitized_html')\n",
    "            if text:\n",
    "                text = re.sub('<.*?>', ' ', text)\n",
    "                article_texts[js['id']] = text\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a071477c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f\"data_files/article_texts.json\",'w') as f:\n",
    "    json.dump(article_texts,f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
